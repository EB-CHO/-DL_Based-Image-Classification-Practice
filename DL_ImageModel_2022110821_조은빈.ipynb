{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UsrVMU60m-si"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, models\n",
        "\n",
        "# Step 1: Device 설정 (GPU 사용 가능 여부 확인)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: STL-10 데이터셋 로드 및 전처리 설정\n",
        "def load_dataset():\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),  # ResNet이 기대하는 입력 크기\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 일반적인 ImageNet 정규화 값\n",
        "    ])\n",
        "\n",
        "    train_dataset = datasets.STL10(root='.', split='train', download=True, transform=transform)\n",
        "    test_dataset = datasets.STL10(root='.', split='test', download=True, transform=transform)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    classes = train_dataset.classes\n",
        "    return train_loader, test_loader, classes"
      ],
      "metadata": {
        "id": "rpLFkmKRnDfE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: ImageNet 사전 학습된 ResNet 모델 불러오기 및 Fine-Tuning 설정\n",
        "model = models.resnet18(pretrained=True)  # ImageNet으로 사전 학습된 ResNet18 사용\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features, 10)  # STL-10 클래스 수에 맞게 출력층 수정\n",
        "model = model.to(device)\n",
        "\n",
        "# 손실 함수와 옵티마이저 설정\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "# 데이터셋 로드\n",
        "train_loader, test_loader, classes = load_dataset()\n",
        "\n",
        "# Step 4: Fine-Tuning 수행\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # 학습 모드로 설정\n",
        "    total_loss = 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)  # GPU로 이동\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "185wdKFmnLaG",
        "outputId": "01e31a9a-1118-42e7-ebbf-44be75b12631"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch [1/5], Loss: 0.6552\n",
            "Epoch [2/5], Loss: 0.1703\n",
            "Epoch [3/5], Loss: 0.1036\n",
            "Epoch [4/5], Loss: 0.0599\n",
            "Epoch [5/5], Loss: 0.0386\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-Tuning 완료 후 모델 가중치 저장\n",
        "torch.save(model.state_dict(), \"STL10-finetuned_model.pth\")"
      ],
      "metadata": {
        "id": "SKJ6J658-cUz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: 모델 평가\n",
        "model.eval()  # 평가 모드로 설정\n",
        "correct, total = 0, 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)  # GPU로 이동\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "Efo1U2MOoo3S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf05667a-d151-4191-c5bb-b0de2965d364"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 95.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: 예측 함수 - 새로운 이미지에 대한 예측 수행\n",
        "def predict(image):\n",
        "    model.eval()\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    input_tensor = preprocess(image).unsqueeze(0).to(device)  # 배치 차원 추가 및 GPU로 이동\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor).squeeze(0).softmax(0)  # 확률값으로 구성된 1차원 배열\n",
        "    class_id = output.argmax().item()  # 예측된 클래스 ID\n",
        "    score = output[class_id].item()  # 해당 클래스의 확률값\n",
        "    class_name = classes[class_id]\n",
        "    print(f\"Predicted: {class_name} ({100 * score:.1f}%)\")\n",
        "\n",
        "    # 1차원 확률 배열 반환\n",
        "    return output"
      ],
      "metadata": {
        "id": "-iLcEwaioxLy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 예시\n",
        "from PIL import Image\n",
        "\n",
        "# 로컬 이미지 파일 경로\n",
        "image_path = \"./Car1.jpg\"\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# 예측 수행 및 확률값 출력\n",
        "probabilities = predict(image)\n",
        "print(\"Class Probabilities:\", probabilities)"
      ],
      "metadata": {
        "id": "a2-m8dC6pgST",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be51d472-16e0-45ce-c30e-ec743566ca92"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: car (100.0%)\n",
            "Class Probabilities: tensor([1.4889e-04, 4.4769e-05, 9.9955e-01, 1.7002e-05, 1.8168e-05, 8.5754e-05,\n",
            "        2.4666e-05, 2.4718e-05, 7.7311e-06, 7.9653e-05], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Serving Try 1"
      ],
      "metadata": {
        "id": "fQ1dPKjeXcs2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi uvicorn torch torchvision pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssVgiAc38EWj",
        "outputId": "4dc45939-62ab-465e-dfe7-b9c5bbcb07ff"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (0.115.4)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/dist-packages (0.32.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.0+cu121)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (10.4.0)\n",
            "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (0.41.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (2.9.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (4.12.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.23.4)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.42.0,>=0.40.0->fastapi) (3.7.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (1.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-multipart"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJjfpaT2-m92",
        "outputId": "3356d628-a2bc-4a29-fae7-4f6fef6b7fe1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (0.0.16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "from fastapi import FastAPI, UploadFile, File\n",
        "from pydantic import BaseModel\n",
        "from io import BytesIO\n",
        "\n",
        "# 모델 및 전처리 설정\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 사전 학습된 모델 로드 및 Fine-Tuning 된 분류층 불러오기\n",
        "model = models.resnet18(pretrained=True)\n",
        "num_features = model.fc.in_features\n",
        "model.fc = torch.nn.Linear(num_features, 10)  # STL-10에 맞게 클래스 수를 10으로 설정\n",
        "model.load_state_dict(torch.load(\"STL10-finetuned_model.pth\", map_location=device))  # Fine-Tuning된 모델 가중치 로드\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# 전처리 파이프라인 설정\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 클래스 이름 (STL-10 클래스)\n",
        "classes = [\"airplane\", \"bird\", \"car\", \"cat\", \"deer\", \"dog\", \"horse\", \"monkey\", \"ship\", \"truck\"]\n",
        "\n",
        "# FastAPI 인스턴스 생성\n",
        "app = FastAPI()\n",
        "\n",
        "# Request 형식 정의\n",
        "class PredictionResponse(BaseModel):\n",
        "    class_name: str\n",
        "    confidence: float\n",
        "\n",
        "# 이미지 예측 함수\n",
        "def predict(image: Image.Image):\n",
        "    input_tensor = preprocess(image).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor).squeeze(0).softmax(0)\n",
        "    class_id = output.argmax().item()\n",
        "    confidence = output[class_id].item()\n",
        "    return classes[class_id], confidence\n",
        "\n",
        "# API 엔드포인트 정의\n",
        "@app.post(\"/predict\", response_model=PredictionResponse)\n",
        "async def predict_image(file: UploadFile = File(...)):\n",
        "    # 이미지 파일 열기\n",
        "    image = Image.open(BytesIO(await file.read())).convert(\"RGB\")\n",
        "    # 예측 수행\n",
        "    class_name, confidence = predict(image)\n",
        "    # 결과 반환\n",
        "    return {\"class_name\": class_name, \"confidence\": confidence}"
      ],
      "metadata": {
        "id": "zH3FXIjZyzXY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff565353-f7cc-49c3-ffb6-41fff9b5cac7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-ab808c648f94>:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"STL10-finetuned_model.pth\", map_location=device))  # Fine-Tuning된 모델 가중치 로드\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# app.py 파일에 Serving 코드 저장하기\n",
        "serving_code = '''\n",
        "import torch\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "from fastapi import FastAPI, UploadFile, File\n",
        "from pydantic import BaseModel\n",
        "from io import BytesIO\n",
        "\n",
        "# 모델 및 전처리 설정\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 사전 학습된 모델 로드 및 Fine-Tuning 된 분류층 불러오기\n",
        "model = models.resnet18(pretrained=True)\n",
        "num_features = model.fc.in_features\n",
        "model.fc = torch.nn.Linear(num_features, 10)  # STL-10에 맞게 클래스 수를 10으로 설정\n",
        "model.load_state_dict(torch.load(\"STL10-finetuned_model.pth\", map_location=device))  # Fine-Tuning된 모델 가중치 로드\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# 전처리 파이프라인 설정\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 클래스 이름 (STL-10 클래스)\n",
        "classes = [\"airplane\", \"bird\", \"car\", \"cat\", \"deer\", \"dog\", \"horse\", \"monkey\", \"ship\", \"truck\"]\n",
        "\n",
        "# FastAPI 인스턴스 생성\n",
        "app = FastAPI()\n",
        "\n",
        "# Request 형식 정의\n",
        "class PredictionResponse(BaseModel):\n",
        "    class_name: str\n",
        "    confidence: float\n",
        "\n",
        "# 이미지 예측 함수\n",
        "def predict(image: Image.Image):\n",
        "    input_tensor = preprocess(image).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor).squeeze(0).softmax(0)\n",
        "    class_id = output.argmax().item()\n",
        "    confidence = output[class_id].item()\n",
        "    return classes[class_id], confidence\n",
        "\n",
        "# API 엔드포인트 정의\n",
        "@app.post(\"/predict\", response_model=PredictionResponse)\n",
        "async def predict_image(file: UploadFile = File(...)):\n",
        "    # 이미지 파일 열기\n",
        "    image = Image.open(BytesIO(await file.read())).convert(\"RGB\")\n",
        "    # 예측 수행\n",
        "    class_name, confidence = predict(image)\n",
        "    # 결과 반환\n",
        "    return {\"class_name\": class_name, \"confidence\": confidence}\n",
        "'''\n",
        "\n",
        "# 파일에 코드 저장\n",
        "with open(\"STL10-serving.py\", \"w\") as f:\n",
        "    f.write(serving_code)"
      ],
      "metadata": {
        "id": "6bsH5uAv9mX8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Serving: ngrok\n",
        "--> Well Executed"
      ],
      "metadata": {
        "id": "BtkOowJsXgAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqqMTXpHIyf9",
        "outputId": "c4ba9605-981f-41ff-99cc-aa05d8b9e601"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# ngrok 인증 토큰 설정\n",
        "ngrok.set_auth_token(\"2oBL7F32G2iIEV5ie5dAumgGMXc_2ZLm9JGC1ZPnNbgwDG6P3\")"
      ],
      "metadata": {
        "id": "msMagSAGCKdO"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# 실행 중인 모든 ngrok 터널 종료\n",
        "ngrok.kill()"
      ],
      "metadata": {
        "id": "qU3slbYzP208"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "import threading\n",
        "\n",
        "# ngrok을 사용하여 포트 8002을 공개합니다.\n",
        "public_url = ngrok.connect(8002, \"http\")\n",
        "print(\"ngrok Public URL:\", public_url)\n",
        "\n",
        "# FastAPI 서버를 백그라운드에서 실행하는 함수\n",
        "def run_app():\n",
        "    uvicorn.run(\"STL10-serving:app\", host=\"0.0.0.0\", port=8002)\n",
        "\n",
        "# 별도의 스레드에서 FastAPI 서버 실행\n",
        "thread = threading.Thread(target=run_app)\n",
        "thread.start()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUYRzuBFLvI9",
        "outputId": "5a3a20c7-5e06-4795-8afb-af2c30efb789"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ngrok Public URL: NgrokTunnel: \"https://b4a1-34-118-243-130.ngrok-free.app\" -> \"http://localhost:8002\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "file_path = \"/content/Car1.jpg\"\n",
        "print(\"File exists:\", os.path.exists(file_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpXghGctLzpn",
        "outputId": "7b670a13-c39b-41f5-a81c-7439a0f2fadd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File exists: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qoX1mRNxV2jR"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}